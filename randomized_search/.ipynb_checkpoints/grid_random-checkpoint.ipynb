{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to compare the performance of tuning the hyperparameters with [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).  First, I am going to create a dataset that has 10,000 samples and 20 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.520216</td>\n",
       "      <td>-0.299523</td>\n",
       "      <td>1.697775</td>\n",
       "      <td>0.152835</td>\n",
       "      <td>-0.071976</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.057001</td>\n",
       "      <td>1.656589</td>\n",
       "      <td>0.059377</td>\n",
       "      <td>0.634026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230848</td>\n",
       "      <td>-2.133668</td>\n",
       "      <td>-0.658056</td>\n",
       "      <td>0.227366</td>\n",
       "      <td>-1.005542</td>\n",
       "      <td>-0.533868</td>\n",
       "      <td>-0.656252</td>\n",
       "      <td>-1.167656</td>\n",
       "      <td>-0.902226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.252605</td>\n",
       "      <td>1.432791</td>\n",
       "      <td>1.561181</td>\n",
       "      <td>-1.456888</td>\n",
       "      <td>-0.325153</td>\n",
       "      <td>-1.757407</td>\n",
       "      <td>1.183243</td>\n",
       "      <td>0.931166</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>-1.833468</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644497</td>\n",
       "      <td>1.259892</td>\n",
       "      <td>1.355751</td>\n",
       "      <td>-1.085283</td>\n",
       "      <td>-1.347220</td>\n",
       "      <td>-0.073796</td>\n",
       "      <td>0.718362</td>\n",
       "      <td>-2.334630</td>\n",
       "      <td>1.531651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-1.118205</td>\n",
       "      <td>-0.335938</td>\n",
       "      <td>-0.979303</td>\n",
       "      <td>0.188338</td>\n",
       "      <td>-0.346252</td>\n",
       "      <td>-1.263341</td>\n",
       "      <td>-1.037886</td>\n",
       "      <td>-0.870959</td>\n",
       "      <td>2.105311</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794894</td>\n",
       "      <td>0.796176</td>\n",
       "      <td>0.193527</td>\n",
       "      <td>-2.070266</td>\n",
       "      <td>-1.183444</td>\n",
       "      <td>-0.231885</td>\n",
       "      <td>1.581976</td>\n",
       "      <td>1.110054</td>\n",
       "      <td>1.610723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334311</td>\n",
       "      <td>1.568198</td>\n",
       "      <td>-0.423843</td>\n",
       "      <td>-0.962124</td>\n",
       "      <td>1.060851</td>\n",
       "      <td>-3.596107</td>\n",
       "      <td>-0.416077</td>\n",
       "      <td>-0.602925</td>\n",
       "      <td>-0.523378</td>\n",
       "      <td>0.834385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636568</td>\n",
       "      <td>-2.537476</td>\n",
       "      <td>-0.355572</td>\n",
       "      <td>1.032740</td>\n",
       "      <td>0.195867</td>\n",
       "      <td>-0.227352</td>\n",
       "      <td>-0.332308</td>\n",
       "      <td>0.813405</td>\n",
       "      <td>-1.037039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.803574</td>\n",
       "      <td>-0.573973</td>\n",
       "      <td>2.605967</td>\n",
       "      <td>0.600801</td>\n",
       "      <td>0.823409</td>\n",
       "      <td>0.494084</td>\n",
       "      <td>-0.398244</td>\n",
       "      <td>1.332191</td>\n",
       "      <td>0.273173</td>\n",
       "      <td>1.089310</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.030162</td>\n",
       "      <td>-1.252967</td>\n",
       "      <td>1.109795</td>\n",
       "      <td>-1.197247</td>\n",
       "      <td>-0.681647</td>\n",
       "      <td>-0.786710</td>\n",
       "      <td>0.833898</td>\n",
       "      <td>-0.258752</td>\n",
       "      <td>0.161887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.520216 -0.299523  1.697775  0.152835 -0.071976  0.002353  0.057001   \n",
       "1  0.252605  1.432791  1.561181 -1.456888 -0.325153 -1.757407  1.183243   \n",
       "2 -1.118205 -0.335938 -0.979303  0.188338 -0.346252 -1.263341 -1.037886   \n",
       "3  0.334311  1.568198 -0.423843 -0.962124  1.060851 -3.596107 -0.416077   \n",
       "4 -0.803574 -0.573973  2.605967  0.600801  0.823409  0.494084 -0.398244   \n",
       "\n",
       "          7         8         9  ...        11        12        13        14  \\\n",
       "0  1.656589  0.059377  0.634026  ...  0.230848 -2.133668 -0.658056  0.227366   \n",
       "1  0.931166  0.967256 -1.833468  ... -1.644497  1.259892  1.355751 -1.085283   \n",
       "2 -0.870959  2.105311  0.892956  ...  0.794894  0.796176  0.193527 -2.070266   \n",
       "3 -0.602925 -0.523378  0.834385  ... -0.636568 -2.537476 -0.355572  1.032740   \n",
       "4  1.332191  0.273173  1.089310  ... -1.030162 -1.252967  1.109795 -1.197247   \n",
       "\n",
       "         15        16        17        18        19  target  \n",
       "0 -1.005542 -0.533868 -0.656252 -1.167656 -0.902226       0  \n",
       "1 -1.347220 -0.073796  0.718362 -2.334630  1.531651       0  \n",
       "2 -1.183444 -0.231885  1.581976  1.110054  1.610723       1  \n",
       "3  0.195867 -0.227352 -0.332308  0.813405 -1.037039       1  \n",
       "4 -0.681647 -0.786710  0.833898 -0.258752  0.161887       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "# make dataset \n",
    "X, y = make_classification(n_samples = 10000, \n",
    "                           n_features=20, \n",
    "                           n_informative=4, \n",
    "                           n_redundant=0, \n",
    "                           random_state=11)\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df['target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I'm going to build a parameter grid for an random forest classifier.  I got the parameter grid from this great [article](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Create the random grid\n",
    "param_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "                'n_estimators': n_estimators}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will find the best hyperparameters for the random forest using GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gridsearch = GridSearchCV(estimator = clf, param_grid = param_grid,\n",
    "                             cv = 3, verbose=2, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 43.3min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 102.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1969 tasks      | elapsed: 139.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 152.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 s, sys: 627 ms, total: 14.9 s\n",
      "Wall time: 2h 32min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100,\n",
       "                                       110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400,\n",
       "                                          1600, 1800, 2000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_gridsearch.fit(df.drop('target', axis = 1), df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9072"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gridsearch.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gridsearch took 2 hours and 32 minutes and got a accuracy of 90.7%.  Now I will try using RandomizedSearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = param_grid, n_iter = 100,\n",
    "                               cv = 3, verbose=2, random_state=11, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 20.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.08 s, sys: 190 ms, total: 7.27 s\n",
      "Wall time: 21min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=None,\n",
       "                                                    oob_sc...\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=11, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf_random.fit(df.drop('target', axis = 1), df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using randomizedsearch I got an accuracy of 90.7% and it took 21 minutes to train. So, I got the same accuracy in significantly less training time using randomizedsearch. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
